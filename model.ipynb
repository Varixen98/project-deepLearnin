{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4952b4c",
   "metadata": {},
   "source": [
    "<h1>Data Preperation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "257e0ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import utilities libraries\n",
    "import os \n",
    "import cv2 \n",
    "import numpy as np \n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import glob\n",
    "import random\n",
    "\n",
    "# import yolo model\n",
    "from ultralytics import YOLO\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a4e68fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO11n-bifpn summary: 217 layers, 1,467,211 parameters, 1,467,195 gradients, 9.4 GFLOPs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(217, 1467211, 1467195, 9.4240512)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load your custom model configuration\n",
    "model = YOLO('yolo11n-bifpn.yaml')\n",
    "\n",
    "# Print info to verify layers are there\n",
    "model.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8af6c111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found source data at: d:\\Data Adji\\Binus\\Semester 5\\DeepLearning\\Project\\brisc2025\\segmentation_task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train: 100%|██████████| 3933/3933 [00:15<00:00, 261.32it/s]\n",
      "Processing test: 100%|██████████| 860/860 [00:03<00:00, 277.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Multiclass Dataset Prepared!\n",
      "Config saved to: data_multiclass.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- CONFIGURATION ---\n",
    "# We create a NEW folder for the multi-class dataset\n",
    "DEST_ROOT = Path(\"yolo_dataset_multiclass\")\n",
    "\n",
    "# Define Class Mapping based on your filenames\n",
    "# gl = glioma (0), me = meningioma (1), pi = pituitary (2)\n",
    "CLASS_MAP = {\n",
    "    'gl': 0, \n",
    "    'me': 1, \n",
    "    'pi': 2\n",
    "}\n",
    "\n",
    "def find_source_root():\n",
    "    current_dir = Path.cwd()\n",
    "    # Priority search locations\n",
    "    candidates = [\n",
    "        current_dir / \"brisc2025\" / \"segmentation_task\",\n",
    "        current_dir / \"segmentation_task\",\n",
    "        current_dir\n",
    "    ]\n",
    "    for path in candidates:\n",
    "        if (path / \"train\").exists():\n",
    "            return path\n",
    "    raise FileNotFoundError(\"Could not find 'segmentation_task' folder!\")\n",
    "\n",
    "def get_class_id(filename):\n",
    "    \"\"\"Determines class ID (0,1,2) from the filename string.\"\"\"\n",
    "    fname = filename.lower()\n",
    "    \n",
    "    # Check for specific codes in the filename\n",
    "    if '_gl_' in fname or 'glioma' in fname:\n",
    "        return 0\n",
    "    elif '_me_' in fname or 'meningioma' in fname:\n",
    "        return 1\n",
    "    elif '_pi_' in fname or 'pituitary' in fname:\n",
    "        return 2\n",
    "    \n",
    "    return None # Unknown class\n",
    "\n",
    "def convert_mask_to_yolo_box(mask_path, class_id):\n",
    "    mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "    if mask is None: return None\n",
    "    \n",
    "    _, thresh = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    labels = []\n",
    "    h_img, w_img = mask.shape[:2]\n",
    "    \n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if w < 3 or h < 3: continue \n",
    "            \n",
    "        x_center = (x + w / 2) / w_img\n",
    "        y_center = (y + h / 2) / h_img\n",
    "        w_norm = w / w_img\n",
    "        h_norm = h / h_img\n",
    "        \n",
    "        # Use the detected Class ID\n",
    "        labels.append(f\"{class_id} {x_center:.6f} {y_center:.6f} {w_norm:.6f} {h_norm:.6f}\")\n",
    "        \n",
    "    return labels\n",
    "\n",
    "def prepare_multiclass_dataset():\n",
    "    if DEST_ROOT.exists():\n",
    "        print(f\"Dataset folder '{DEST_ROOT}' already exists. Delete it if you want to re-create it.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        source_root = find_source_root()\n",
    "        print(f\"Found source data at: {source_root}\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return\n",
    "\n",
    "    for split in [\"train\", \"test\"]:\n",
    "        src_path = source_root / split\n",
    "        img_src = src_path / \"images\" if (src_path / \"images\").exists() else src_path / \"image\"\n",
    "        mask_src = src_path / \"masks\" if (src_path / \"masks\").exists() else src_path / \"mask\"\n",
    "        \n",
    "        img_dst = DEST_ROOT / \"images\" / split\n",
    "        lbl_dst = DEST_ROOT / \"labels\" / split\n",
    "        \n",
    "        img_dst.mkdir(parents=True, exist_ok=True)\n",
    "        lbl_dst.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        images = list(img_src.glob(\"*.*\"))\n",
    "        valid_exts = {'.jpg', '.jpeg', '.png', '.bmp'}\n",
    "        images = [x for x in images if x.suffix.lower() in valid_exts]\n",
    "        \n",
    "        # --- TQDM ADDED HERE ---\n",
    "        skipped_count = 0\n",
    "        for img_path in tqdm(images, desc=f\"Processing {split}\"):\n",
    "            # 1. Determine Class\n",
    "            class_id = get_class_id(img_path.name)\n",
    "            \n",
    "            if class_id is None:\n",
    "                skipped_count += 1\n",
    "                continue # Skip images where we can't determine the tumor type\n",
    "            \n",
    "            # 2. Find Mask\n",
    "            possible_masks = [\n",
    "                mask_src / img_path.name,\n",
    "                mask_src / img_path.with_suffix('.png').name,\n",
    "                mask_src / img_path.with_suffix('.jpg').name\n",
    "            ]\n",
    "            \n",
    "            labels_written = False\n",
    "            for mask_p in possible_masks:\n",
    "                if mask_p.exists():\n",
    "                    yolo_labels = convert_mask_to_yolo_box(mask_p, class_id)\n",
    "                    if yolo_labels:\n",
    "                        # Copy Image ONLY if we have a valid label\n",
    "                        shutil.copy(img_path, img_dst / img_path.name)\n",
    "                        \n",
    "                        with open(lbl_dst / img_path.with_suffix('.txt').name, 'w') as f:\n",
    "                            f.write('\\n'.join(yolo_labels))\n",
    "                        labels_written = True\n",
    "                    break\n",
    "            \n",
    "        if skipped_count > 0:\n",
    "            print(f\"  Warning: Skipped {skipped_count} images in {split} (unknown class name in file).\")\n",
    "\n",
    "    # Create YAML config for Multiclass\n",
    "    yaml_content = f\"\"\"\n",
    "        path: {DEST_ROOT.resolve().as_posix()}\n",
    "        train: images/train\n",
    "        val: images/test\n",
    "        test: images/test\n",
    "\n",
    "        # Classes\n",
    "        nc: 3\n",
    "        names: ['glioma', 'meningioma', 'pituitary']\n",
    "        \"\"\"\n",
    "    with open(\"data_multiclass.yaml\", \"w\") as f:\n",
    "        f.write(yaml_content)\n",
    "    print(\"\\n✅ Multiclass Dataset Prepared!\")\n",
    "    print(f\"Config saved to: data_multiclass.yaml\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    prepare_multiclass_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46f6c908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "Loading pre-trained weights...\n",
      "Transferred 196/586 items from pretrained weights\n",
      "New https://pypi.org/project/ultralytics/8.3.235 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.233  Python-3.11.14 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=data_multiclass.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n-bifpn.yaml, momentum=0.937, mosaic=1.0, multi_scale=False, name=run1, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=yolo11n.pt, profile=False, project=BrainTumor_BiFPN, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=D:\\Data Adji\\Binus\\Semester 5\\DeepLearning\\Project\\BrainTumor_BiFPN\\run1, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  8                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  9                  -1  1     41344  ultralytics.nn.modules.block.SPPF            [128, 128, 5]                 \n",
      " 10                  -1  1     63424  ultralytics.nn.modules.block.C2PSA           [128, 128, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1     94912  ultralytics.nn.modules.block.C3k2            [256, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 18             [-1, 2]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1      8112  ultralytics.nn.modules.block.C3k2            [128, 32, 1, False]           \n",
      " 20                  -1  1      1154  ultralytics.nn.modules.conv.CBAM             [32, 7]                       \n",
      " 21                  -1  1      9280  ultralytics.nn.modules.conv.Conv             [32, 32, 3, 2]                \n",
      " 22            [-1, 16]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1     21856  ultralytics.nn.modules.block.C3k2            [96, 64, 1, False]            \n",
      " 24                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 25            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 26                  -1  1     95232  ultralytics.nn.modules.block.C3k2            [192, 128, 1, True]           \n",
      " 27                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 28            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 29                  -1  1    103424  ultralytics.nn.modules.block.C3k2            [256, 128, 1, True]           \n",
      " 30        [19, 23, 26]  1    267321  ultralytics.nn.modules.head.Detect           [3, [32, 64, 128]]            \n",
      "YOLO11n-bifpn summary: 217 layers, 1,467,211 parameters, 1,467,195 gradients, 9.4 GFLOPs\n",
      "\n",
      "Transferred 586/586 items from pretrained weights\n",
      "Freezing layer 'model.30.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 160.035.1 MB/s, size: 23.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\Data Adji\\Binus\\Semester 5\\DeepLearning\\Project\\yolo_dataset_multiclass\\labels\\train... 3933 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 3933/3933 1.2Kit/s 3.2s0.1s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: D:\\Data Adji\\Binus\\Semester 5\\DeepLearning\\Project\\yolo_dataset_multiclass\\labels\\train.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 120.026.8 MB/s, size: 23.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Data Adji\\Binus\\Semester 5\\DeepLearning\\Project\\yolo_dataset_multiclass\\labels\\test... 860 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 860/860 972.1it/s 0.9s0.1s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: D:\\Data Adji\\Binus\\Semester 5\\DeepLearning\\Project\\yolo_dataset_multiclass\\labels\\test.cache\n",
      "Plotting labels to D:\\Data Adji\\Binus\\Semester 5\\DeepLearning\\Project\\BrainTumor_BiFPN\\run1\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 95 weight(decay=0.0), 104 weight(decay=0.0005), 102 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mD:\\Data Adji\\Binus\\Semester 5\\DeepLearning\\Project\\BrainTumor_BiFPN\\run1\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/50     0.998G      2.465      3.366      2.906          2        640: 100% ━━━━━━━━━━━━ 984/984 2.8it/s 5:51<0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 3.6it/s 29.7s0.3s\n",
      "                   all        860        916      0.417      0.438      0.317      0.165\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/50      1.14G      1.803      2.372      2.279          1        640: 100% ━━━━━━━━━━━━ 984/984 4.5it/s 3:38<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 8.4it/s 12.8s0.1s\n",
      "                   all        860        916      0.394      0.558      0.452       0.26\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/50      1.14G      1.611       2.11      2.068          1        640: 100% ━━━━━━━━━━━━ 984/984 5.5it/s 2:58<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 8.4it/s 12.9s0.1s\n",
      "                   all        860        916      0.535      0.537      0.537      0.326\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/50      1.14G      1.529      1.935      1.939          1        640: 100% ━━━━━━━━━━━━ 984/984 4.8it/s 3:26<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 7.4it/s 14.6s0.1s\n",
      "                   all        860        916      0.639      0.609      0.652      0.413\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/50      1.14G      1.475      1.777      1.896          4        640: 100% ━━━━━━━━━━━━ 984/984 4.4it/s 3:41<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 5.9it/s 18.3s0.2s\n",
      "                   all        860        916       0.66       0.63      0.673      0.419\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/50      1.14G      1.419      1.675      1.844          1        640: 100% ━━━━━━━━━━━━ 984/984 3.8it/s 4:16<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 7.3it/s 14.7s0.1s\n",
      "                   all        860        916      0.747      0.676      0.741      0.474\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/50      1.14G      1.374      1.578      1.804          1        640: 100% ━━━━━━━━━━━━ 984/984 4.4it/s 3:41<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 7.4it/s 14.5s0.1s\n",
      "                   all        860        916      0.734      0.663      0.724      0.473\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/50      1.14G      1.365      1.533      1.787          1        640: 100% ━━━━━━━━━━━━ 984/984 4.6it/s 3:36<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 7.0it/s 15.4s0.1s\n",
      "                   all        860        916      0.726      0.707      0.761       0.51\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/50      1.14G       1.33       1.48      1.746          1        640: 100% ━━━━━━━━━━━━ 984/984 5.0it/s 3:16<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 8.0it/s 13.5s0.1s\n",
      "                   all        860        916      0.753      0.698      0.767      0.501\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/50      1.14G      1.314      1.458      1.741          1        640: 100% ━━━━━━━━━━━━ 984/984 5.1it/s 3:14<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 7.1it/s 15.3s0.1s\n",
      "                   all        860        916      0.744      0.715      0.774      0.515\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/50      1.14G      1.318      1.461      1.746          1        640: 100% ━━━━━━━━━━━━ 984/984 4.7it/s 3:31<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 6.8it/s 15.8s0.1s\n",
      "                   all        860        916      0.758       0.74      0.791      0.521\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/50      1.14G      1.294      1.417       1.71          1        640: 100% ━━━━━━━━━━━━ 984/984 4.9it/s 3:19<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 8.1it/s 13.4s0.1s\n",
      "                   all        860        916      0.826      0.719      0.799      0.547\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/50      1.14G      1.276      1.375      1.703          1        640: 100% ━━━━━━━━━━━━ 984/984 5.1it/s 3:12<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 8.1it/s 13.4s0.1s\n",
      "                   all        860        916      0.782      0.726        0.8      0.555\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/50      1.14G      1.268      1.342      1.692          0        640: 100% ━━━━━━━━━━━━ 984/984 5.1it/s 3:12<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 8.1it/s 13.3s0.1s\n",
      "                   all        860        916      0.808      0.732      0.819      0.559\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/50      1.14G      1.231      1.297      1.661          4        640: 100% ━━━━━━━━━━━━ 984/984 5.1it/s 3:13<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 8.1it/s 13.4s0.1s\n",
      "                   all        860        916      0.806      0.777      0.833      0.581\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/50      1.14G      1.245      1.304      1.677          1        640: 100% ━━━━━━━━━━━━ 984/984 5.1it/s 3:12<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 8.1it/s 13.3s0.1s\n",
      "                   all        860        916       0.77      0.754      0.805      0.564\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/50      1.14G      1.241      1.257      1.659          4        640: 100% ━━━━━━━━━━━━ 984/984 5.1it/s 3:13<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 8.1it/s 13.4s0.1s\n",
      "                   all        860        916      0.818      0.726      0.832      0.571\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/50      1.14G      1.205      1.228      1.638          1        640: 100% ━━━━━━━━━━━━ 984/984 5.1it/s 3:14<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 8.1it/s 13.3s0.1s\n",
      "                   all        860        916      0.819      0.772       0.84      0.585\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/50      1.14G      1.192      1.197      1.621          1        640: 100% ━━━━━━━━━━━━ 984/984 5.3it/s 3:05<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 8.3it/s 13.0s0.1s\n",
      "                   all        860        916      0.833      0.776      0.842      0.597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/50      1.14G      1.193      1.202      1.621          2        640: 100% ━━━━━━━━━━━━ 984/984 5.3it/s 3:05<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 8.2it/s 13.2s0.1s\n",
      "                   all        860        916      0.821      0.759      0.838      0.592\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/50      1.14G      1.186      1.175      1.613          2        640: 100% ━━━━━━━━━━━━ 984/984 5.3it/s 3:04<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 8.2it/s 13.2s0.1s\n",
      "                   all        860        916      0.821      0.787      0.852      0.593\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/50      1.14G      1.171       1.13      1.601          3        640: 100% ━━━━━━━━━━━━ 984/984 5.4it/s 3:04<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 8.5it/s 12.8s0.1s\n",
      "                   all        860        916      0.826      0.756      0.842      0.595\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/50      1.14G      1.159      1.137       1.59          1        640: 100% ━━━━━━━━━━━━ 984/984 5.5it/s 2:57<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 8.5it/s 12.7s0.1s\n",
      "                   all        860        916      0.797      0.791      0.847      0.604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/50      1.14G      1.164      1.137      1.586          1        640: 100% ━━━━━━━━━━━━ 984/984 5.6it/s 2:57<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 8.4it/s 12.9s0.1s\n",
      "                   all        860        916      0.826      0.767      0.847      0.609\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/50      1.14G      1.136      1.092      1.563          0        640: 100% ━━━━━━━━━━━━ 984/984 5.5it/s 2:57<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 8.4it/s 12.9s0.1s\n",
      "                   all        860        916       0.82       0.79       0.86      0.613\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/50      1.14G      1.132      1.094      1.555          2        640: 100% ━━━━━━━━━━━━ 984/984 5.5it/s 2:59<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 8.4it/s 12.9s0.1s\n",
      "                   all        860        916      0.834      0.784      0.856      0.609\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/50      1.14G      1.107      1.069      1.533          1        640: 100% ━━━━━━━━━━━━ 984/984 5.5it/s 2:59<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 8.3it/s 13.1s0.1s\n",
      "                   all        860        916      0.833      0.802      0.869      0.626\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/50      1.14G      1.109      1.047      1.533          1        640: 100% ━━━━━━━━━━━━ 984/984 5.0it/s 3:16<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 7.5it/s 14.3s0.1s\n",
      "                   all        860        916      0.838      0.779      0.855      0.613\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/50      1.14G       1.09      1.048      1.519          2        640: 100% ━━━━━━━━━━━━ 984/984 4.9it/s 3:23<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 8.3it/s 13.0s0.1s\n",
      "                   all        860        916      0.862      0.796      0.872      0.625\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/50      1.14G      1.084      1.037      1.515          3        640: 100% ━━━━━━━━━━━━ 984/984 5.5it/s 2:60<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 8.2it/s 13.2s0.1s\n",
      "                   all        860        916      0.845       0.79      0.861      0.613\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      31/50      1.14G      1.081      1.003      1.514          2        640: 100% ━━━━━━━━━━━━ 984/984 4.8it/s 3:23<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 7.5it/s 14.4s0.1s\n",
      "                   all        860        916      0.852      0.806       0.87      0.625\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      32/50      1.14G      1.073      0.989      1.506          1        640: 100% ━━━━━━━━━━━━ 984/984 4.9it/s 3:21<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 7.6it/s 14.3s0.1s\n",
      "                   all        860        916      0.843      0.808      0.869      0.638\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      33/50      1.14G      1.073     0.9887      1.506          1        640: 100% ━━━━━━━━━━━━ 984/984 5.1it/s 3:14<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 8.2it/s 13.2s0.1s\n",
      "                   all        860        916       0.84      0.824      0.877      0.634\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      34/50      1.14G      1.048     0.9638      1.493          2        640: 100% ━━━━━━━━━━━━ 984/984 5.1it/s 3:11<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 8.1it/s 13.3s0.1s\n",
      "                   all        860        916      0.842      0.814      0.875      0.638\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      35/50      1.14G      1.064     0.9668      1.501          4        640: 100% ━━━━━━━━━━━━ 984/984 5.1it/s 3:11<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 8.1it/s 13.3s0.1s\n",
      "                   all        860        916      0.888      0.792      0.879      0.631\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      36/50      1.14G      1.042     0.9456       1.48          1        640: 100% ━━━━━━━━━━━━ 984/984 5.4it/s 3:04<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 8.3it/s 12.9s0.1s\n",
      "                   all        860        916      0.873      0.814      0.886      0.642\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      37/50      1.14G      1.045     0.9401      1.487          2        640: 100% ━━━━━━━━━━━━ 984/984 5.4it/s 3:01<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 7.5it/s 14.5s0.1s\n",
      "                   all        860        916      0.872      0.817      0.888      0.649\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      38/50      1.14G      1.048     0.9284      1.487          1        640: 100% ━━━━━━━━━━━━ 984/984 4.9it/s 3:19<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 7.7it/s 14.0s0.1s\n",
      "                   all        860        916      0.879      0.813      0.885      0.651\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      39/50      1.14G      1.032     0.9193      1.482          1        640: 100% ━━━━━━━━━━━━ 984/984 5.0it/s 3:17<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 7.6it/s 14.1s0.1s\n",
      "                   all        860        916      0.885      0.798      0.883      0.642\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      40/50      1.14G      1.032     0.9123      1.477          1        640: 100% ━━━━━━━━━━━━ 984/984 5.2it/s 3:11<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 8.1it/s 13.3s0.1s\n",
      "                   all        860        916      0.853      0.815      0.877       0.63\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      41/50      1.14G     0.9342     0.7884      1.386          1        640: 100% ━━━━━━━━━━━━ 984/984 5.2it/s 3:09<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 8.2it/s 13.1s0.1s\n",
      "                   all        860        916      0.864      0.808      0.887      0.647\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      42/50      1.14G     0.9234     0.7475      1.375          1        640: 100% ━━━━━━━━━━━━ 984/984 5.2it/s 3:10<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 7.8it/s 13.8s0.1s\n",
      "                   all        860        916      0.885      0.821      0.892      0.656\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      43/50      1.14G     0.9226     0.7452      1.375          1        640: 100% ━━━━━━━━━━━━ 984/984 5.2it/s 3:08<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 8.4it/s 12.9s0.1s\n",
      "                   all        860        916      0.883      0.812       0.89      0.651\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      44/50      1.14G     0.9179     0.7351      1.378          1        640: 100% ━━━━━━━━━━━━ 984/984 5.4it/s 3:02<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 8.3it/s 13.0s0.1s\n",
      "                   all        860        916      0.879      0.829      0.895      0.654\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      45/50      1.14G     0.9102     0.7273      1.361          1        640: 100% ━━━━━━━━━━━━ 984/984 5.4it/s 3:02<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 8.1it/s 13.3s0.1s\n",
      "                   all        860        916      0.877      0.827      0.895       0.66\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      46/50      1.14G     0.9059     0.7257      1.366          1        640: 100% ━━━━━━━━━━━━ 984/984 5.4it/s 3:01<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 8.3it/s 13.1s0.1s\n",
      "                   all        860        916      0.866      0.835      0.895      0.658\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      47/50      1.14G     0.9017     0.7082       1.36          1        640: 100% ━━━━━━━━━━━━ 984/984 5.4it/s 3:01<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 8.4it/s 12.9s0.1s\n",
      "                   all        860        916      0.875       0.83      0.895      0.657\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      48/50      1.14G     0.8979     0.7148      1.354          1        640: 100% ━━━━━━━━━━━━ 984/984 5.4it/s 3:01<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 8.2it/s 13.2s0.1s\n",
      "                   all        860        916      0.873      0.839      0.898      0.661\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      49/50      1.14G     0.8884     0.7067      1.344          3        640: 100% ━━━━━━━━━━━━ 984/984 5.4it/s 3:01<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 8.2it/s 13.1s0.1s\n",
      "                   all        860        916      0.856      0.844      0.897      0.658\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      50/50      1.14G     0.8921     0.7057      1.352          1        640: 100% ━━━━━━━━━━━━ 984/984 5.4it/s 3:01<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 8.4it/s 12.9s0.1s\n",
      "                   all        860        916      0.862      0.842      0.898      0.657\n",
      "\n",
      "50 epochs completed in 2.926 hours.\n",
      "Optimizer stripped from D:\\Data Adji\\Binus\\Semester 5\\DeepLearning\\Project\\BrainTumor_BiFPN\\run1\\weights\\last.pt, 3.4MB\n",
      "Optimizer stripped from D:\\Data Adji\\Binus\\Semester 5\\DeepLearning\\Project\\BrainTumor_BiFPN\\run1\\weights\\best.pt, 3.4MB\n",
      "\n",
      "Validating D:\\Data Adji\\Binus\\Semester 5\\DeepLearning\\Project\\BrainTumor_BiFPN\\run1\\weights\\best.pt...\n",
      "Ultralytics 8.3.233  Python-3.11.14 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "YOLO11n-bifpn summary (fused): 122 layers, 1,461,627 parameters, 0 gradients, 9.2 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 108/108 9.6it/s 11.3s<0.2s\n",
      "                   all        860        916      0.877      0.838      0.898      0.661\n",
      "                glioma        254        296      0.832      0.669      0.781      0.536\n",
      "            meningioma        306        311      0.938      0.968      0.984      0.809\n",
      "             pituitary        300        309       0.86      0.878      0.929      0.638\n",
      "Speed: 0.4ms preprocess, 6.8ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mD:\\Data Adji\\Binus\\Semester 5\\DeepLearning\\Project\\BrainTumor_BiFPN\\run1\u001b[0m\n",
      "Training Complete!\n"
     ]
    }
   ],
   "source": [
    "def train_custom_model():\n",
    "    print(f\"Using Device: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    # 1. Initialize your Custom Architecture\n",
    "    # This reads the YAML we fixed (with the correct channel sizes)\n",
    "    model = YOLO('yolo11n-bifpn.yaml') \n",
    "\n",
    "    # 2. Transfer Learning\n",
    "    # We load standard YOLOv11n weights. \n",
    "    # The backbone will match. The new BiFPN layers will start with random weights.\n",
    "    try:\n",
    "        print(\"Loading pre-trained weights...\")\n",
    "        model.load('yolo11n.pt') \n",
    "    except Exception as e:\n",
    "        print(\"Note: Partial weight loading is expected because architecture changed.\")\n",
    "\n",
    "    # 3. Start Training\n",
    "    # VRAM NOTE: I only use batch=4 because my vram is 4GB. It is very tight for BiFPN+CBAM.\n",
    "    model.train(\n",
    "        data='data_multiclass.yaml',         \n",
    "        epochs=50,               \n",
    "        imgsz=640,               \n",
    "        batch=4,                  \n",
    "        device=0,                \n",
    "        workers=2,                \n",
    "        project='BrainTumor_BiFPN', \n",
    "        name='run1',              \n",
    "        optimizer='AdamW',      \n",
    "        lr0=0.001,                \n",
    "        cos_lr=True,             \n",
    "        amp=True,                 \n",
    "        exist_ok=True      \n",
    "    )\n",
    "    \n",
    "    print(\"Training Complete!\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # This line is REQUIRED for Windows to prevent crashing\n",
    "    torch.multiprocessing.freeze_support()\n",
    "    train_custom_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ba6f061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 d:\\Data Adji\\Binus\\Semester 5\\DeepLearning\\Project\\yolo_dataset_multiclass\\images\\test\\brisc2025_test_00377_me_ax_t1.jpg: 640x640 1 meningioma, 112.7ms\n",
      "Speed: 7.0ms preprocess, 112.7ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mD:\\Data Adji\\Binus\\Semester 5\\DeepLearning\\Project\\runs\\detect\\predict6\u001b[0m\n",
      "\n",
      "image 1/1 d:\\Data Adji\\Binus\\Semester 5\\DeepLearning\\Project\\yolo_dataset_multiclass\\images\\test\\brisc2025_test_00114_gl_co_t1.jpg: 640x640 1 glioma, 51.0ms\n",
      "Speed: 6.0ms preprocess, 51.0ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mD:\\Data Adji\\Binus\\Semester 5\\DeepLearning\\Project\\runs\\detect\\predict6\u001b[0m\n",
      "\n",
      "image 1/1 d:\\Data Adji\\Binus\\Semester 5\\DeepLearning\\Project\\yolo_dataset_multiclass\\images\\test\\brisc2025_test_00238_gl_sa_t1.jpg: 640x640 1 glioma, 50.7ms\n",
      "Speed: 5.5ms preprocess, 50.7ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mD:\\Data Adji\\Binus\\Semester 5\\DeepLearning\\Project\\runs\\detect\\predict6\u001b[0m\n",
      "Press any key to close the image windows...\n"
     ]
    }
   ],
   "source": [
    "# 1. Load your best model\n",
    "model = YOLO('BrainTumor_BiFPN/run1/weights/best.pt')\n",
    "\n",
    "# 2. Get a random image from the test set\n",
    "test_images = glob.glob('yolo_dataset_multiclass/images/test/*.jpg')\n",
    "if not test_images:\n",
    "    print(\"No images found in test folder!\")\n",
    "    exit()\n",
    "\n",
    "# Pick 3 random images to test\n",
    "for i in range(3):\n",
    "    img_path = random.choice(test_images)\n",
    "    \n",
    "    # 3. Predict\n",
    "    # conf=0.4 means \"Only show me if you are 40% sure\"\n",
    "    results = model.predict(img_path, iou=0.4, conf=0.4, max_det=1, save=True) \n",
    "\n",
    "    # 4. Show Result\n",
    "    for result in results:\n",
    "        res_plotted = result.plot()\n",
    "        cv2.imshow(f\"Result {i+1}\", res_plotted)\n",
    "\n",
    "print(\"Press any key to close the image windows...\")\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99be844a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your trained weights\n",
    "model = YOLO('BrainTumor_BiFPN/run1/weights/best.pt')\n",
    "\n",
    "# Export to ONNX (opset=12 is most compatible for web)\n",
    "# 'dynamic=False' helps keeping it simpler for basic inference\n",
    "model.export(format='onnx', opset=12, dynamic=False)\n",
    "\n",
    "print(\"Exporting model 'best.onnx' in weights folder.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLPytorchCVENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
